{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matprint(mat, fmt=\"g\"):\n",
    "    \"\"\"\n",
    "    Pour une un print plus clair de la matrice\n",
    "    https://gist.github.com/braingineer/d801735dac07ff3ac4d746e1f218ab75\n",
    "    \"\"\"\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons des données synthétiques gaussiennes. Ici nous nous intéresserons dans un premier temps au cas où $m=2$. (Binary MTL Supervised Principal Component Analysis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme non distribué 2 taches 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inutile, puisque la première étape consiste à calculer les moyennes empiriques\n",
    "# enfait si c'est quand même utile pour générer les données X\n",
    "\n",
    "def mean_matrix(m, k, p, l, h):\n",
    "    \"\"\"\n",
    "    Retourne une matrice M de taille pxm*k contenant\n",
    "    les moyennes de chaque composante de chaque vecteur aléatoire\n",
    "    pour l'instant les moyennes sont tirées aléatoirement \n",
    "    suivant la loi uniforme sur l, h (pas convaincu par ce choix)\n",
    "    m est le nombre de classes\n",
    "    k est le nombre de taches\n",
    "    p est le nombre de features\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    M = []\n",
    "    tmp = []\n",
    "    for task in range(k):\n",
    "        tmp = []\n",
    "        for classe in range(m):\n",
    "            # on crée un vecteur de moyennes égales pour chaque classes\n",
    "            # de sorte à créer des classes gravitant autour d'une meme moyenne\n",
    "            tmp.append(np.ones((p,1))*np.random.uniform(low = 0.0, high = h))\n",
    "        M.append(tmp)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238],\n",
      "       [7.49080238]]), array([[19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613],\n",
      "       [19.01428613]])], [array([[14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884],\n",
      "       [14.63987884]]), array([[11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968],\n",
      "       [11.97316968]])]]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "n_t = [[100,100], [100,100]]\n",
    "n = 400\n",
    "p = 20\n",
    "m = 2\n",
    "t = 2\n",
    "# 2 taches, 2 classes, p = 20\n",
    "M = mean_matrix(m, t, p, 0., 20.)\n",
    "print(M)\n",
    "\n",
    "# pour plusieurs taches\n",
    "# M = mean_matrix(2, 3, 10, 0., 2.)\n",
    "# print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_synthetic_data(n, p, m, t, n_t, M):\n",
    "    \"\"\"\n",
    "    Renvoie un tableau de données synthétiques gaussiennes. X[0] accède aux données de la premiere tache.\n",
    "    X[0][1] accede aux données de la deuxieme classe de la premiere tache.\n",
    "    (vecteurs gaussiens de taille n_j * p tq sum(n_j for j) = n)\n",
    "    à partir du nombre d'échantillons n de taille p et du nombre de classe m.\n",
    "    t est le nombre de tâches\n",
    "    n_t est un vecteur comprenant les différentes valeurs n_j pour chaque task\n",
    "    M est la matrice des moyennes de chaque composante \n",
    "    de chaque vecteur aléatoire\n",
    "    \"\"\"\n",
    "    # assert(sum(n_j)/n==1\n",
    "    np.random.seed(55)\n",
    "    X = []\n",
    "    tmp = []\n",
    "    for task in range(t):\n",
    "        # pour une tache on a m classes\n",
    "        tmp = []\n",
    "        for k in range(m):\n",
    "            X_k = np.empty((n_t[task][k], p))\n",
    "            # on prendra la transposée a la fin\n",
    "            #print( n_t[task][k])\n",
    "            for j in range(n_t[task][k]):\n",
    "                # on crée n_j[task][k] vecteurs aléatoires de taille 1xp\n",
    "                # std = 1?\n",
    "                X_k[j] = np.random.normal(M[task][k][0], 1, size=(1, p))\n",
    "                # indice 0 parce que c'est toujours la meme moyenne dans M (pour l'instant ?)\n",
    "            X_k = np.transpose(X_k)\n",
    "            #print(k)\n",
    "            tmp.append(X_k)\n",
    "            # print(\"tmp = \", tmp)\n",
    "        X.append(tmp)\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[5.86707126, 6.10869964, 6.8481636 , ..., 6.70465058, 7.13620665,\n",
       "          7.0796798 ],\n",
       "         [7.38901844, 6.49734774, 6.68761084, ..., 6.85227159, 6.16881535,\n",
       "          8.6474948 ],\n",
       "         [5.68101128, 7.32133649, 8.38939155, ..., 7.23735153, 7.240923  ,\n",
       "          8.19763442],\n",
       "         ...,\n",
       "         [8.19315428, 8.28602821, 6.76275903, ..., 7.46703351, 7.30520097,\n",
       "          6.36542667],\n",
       "         [8.37918422, 5.91960822, 7.40346267, ..., 7.22244457, 6.26215294,\n",
       "          8.24851755],\n",
       "         [8.21302218, 6.3310156 , 8.78922099, ..., 7.04150814, 8.5715068 ,\n",
       "          8.55317705]]),\n",
       "  array([[18.84869579, 19.96198015, 16.94794889, ..., 19.83140178,\n",
       "          20.26267812, 20.40687231],\n",
       "         [18.29754695, 20.27570849, 19.11504899, ..., 19.29524154,\n",
       "          19.39791674, 19.38718174],\n",
       "         [17.54862159, 19.02202601, 18.11224915, ..., 20.63372715,\n",
       "          18.77579339, 19.48599358],\n",
       "         ...,\n",
       "         [18.91678072, 18.86403672, 21.14295055, ..., 19.11447701,\n",
       "          20.52806446, 18.45021578],\n",
       "         [19.31355318, 20.05696618, 19.44967959, ..., 20.08774957,\n",
       "          20.00272803, 19.4092906 ],\n",
       "         [17.77661763, 18.78571201, 19.09735098, ..., 20.43155056,\n",
       "          19.08505029, 19.50313636]])],\n",
       " [array([[14.9654045 , 14.45632469, 13.69320934, ..., 13.138391  ,\n",
       "          14.89597555, 15.3351853 ],\n",
       "         [15.12352371, 14.78033277, 14.47287755, ..., 15.59532916,\n",
       "          15.11991787, 14.08354723],\n",
       "         [14.6789721 , 13.36545632, 14.69742981, ..., 14.05579225,\n",
       "          13.43441051, 14.3790668 ],\n",
       "         ...,\n",
       "         [14.38684013, 14.00225587, 16.32583425, ..., 14.34550193,\n",
       "          16.03511886, 13.90008519],\n",
       "         [15.31844419, 14.38096973, 13.53267064, ..., 15.19186072,\n",
       "          15.62162328, 14.01831079],\n",
       "         [15.03449809, 13.64996697, 14.06632978, ..., 16.59790299,\n",
       "          16.76144411, 15.74374353]]),\n",
       "  array([[11.84877594, 11.57549773, 10.98981058, ..., 13.93565087,\n",
       "          12.81862821, 11.7068833 ],\n",
       "         [12.05748113, 12.22415603, 11.48700566, ..., 11.34854646,\n",
       "          10.98556693, 12.37872348],\n",
       "         [13.62512813, 13.30572525,  9.86743783, ..., 12.72246315,\n",
       "          10.99553964, 12.36907476],\n",
       "         ...,\n",
       "         [11.4452798 , 10.8678705 , 10.71917776, ..., 13.22627259,\n",
       "          11.92320574, 12.74715472],\n",
       "         [11.82586966, 10.84869001, 11.44565976, ..., 11.30540767,\n",
       "          12.38188164, 13.35228893],\n",
       "         [13.1240355 , 12.26314658, 11.24544196, ..., 13.12319558,\n",
       "          11.14893042, 10.56857004]])]]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = gaussian_synthetic_data(n, p, m, t, n_t, M)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(X, split_rate, nb_tasks, nb_classes):\n",
    "    \"\"\"\n",
    "    Retourne une matrice de données de tests, et une matrice d'entrainement\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    tmp_test = []\n",
    "    tmp_train = []\n",
    "    n_t_train = []\n",
    "    n_t_test = []\n",
    "    for t in range(nb_tasks):\n",
    "        tmp_test = []\n",
    "        tmp_train = []\n",
    "        tmp_nt_train = []\n",
    "        tmp_nt_test = []\n",
    "        for l in range(nb_classes):\n",
    "            decoupe = int(split_rate*X[t][l].shape[1])\n",
    "            tmp_train.append(X[t][l][:, :decoupe])\n",
    "            tmp_test.append(X[t][l][:, decoupe:])\n",
    "            tmp_nt_train.append(decoupe)\n",
    "            tmp_nt_test.append(X[t][l].shape[1]-decoupe)\n",
    "        n_t_train.append(tmp_nt_train)\n",
    "        n_t_test.append(tmp_nt_test)\n",
    "        X_train.append(tmp_train)\n",
    "        X_test.append(tmp_test)\n",
    "    return X_train, X_test, n_t_train, n_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[80, 80], [80, 80]]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, n_t_train, n_t_test = train_test_split_data(X, 0.8, 2, 2)\n",
    "n_t_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut aussi créer le vecteur $\\tilde{y}\\in\\mathbb{R}^{2k}$, qui contiendra les labels associées aux données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(nb_tasks, nb_classes):\n",
    "    \"\"\"\n",
    "    Crée le vecteurs y_tilde contenant les labels associés aux données.\n",
    "    Ici on le fait pour deux 2 tâches et pour deux classes.\n",
    "    \"\"\"\n",
    "    y = np.empty((nb_classes*nb_tasks))\n",
    "    for t in range(0, nb_classes*nb_tasks-1, 2):\n",
    "        y[t] = -1\n",
    "        y[t+1] = 1\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "y = create_labels(2,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ère etape\n",
    "Calcul des moyennes empiriques, et calcul de la matrice $M\\in\\mathbb{R}^{p\\times 2k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas fait le cas du j=j' mais j'ai pas l'impression que c'est nécessaire en tout cas pas ici ?\n",
    "\n",
    "def empirical_mean(nb_tasks, nb_classes, X, p, n_t):\n",
    "    \"\"\"\n",
    "    compute empirical mean for data X\n",
    "    return an 1xp vector being the empirical mean for the random vector X_{tj}\n",
    "    retourne la matrice M\n",
    "    \"\"\"\n",
    "    M = np.empty((nb_classes*nb_tasks, p))\n",
    "    for t in range(nb_tasks):\n",
    "        for l in range(nb_classes):\n",
    "            #print(X[t][l].dot(np.ones((n_t[t][l]))).shape)\n",
    "            # print(t*nb_classes+l)\n",
    "            M[t*nb_classes+l] = X[t][l].dot(np.ones((n_t[t][l])))\n",
    "            M[t*nb_classes+l] /= n_t[t][l]\n",
    "            print(f\"class {t*nb_classes+l} empirical mean = {np.mean(M[t*nb_classes+l])}\")\n",
    "    return np.transpose(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 empirical mean = 7.51059925787292\n",
      "class 1 empirical mean = 19.018588668707316\n",
      "class 2 empirical mean = 14.64865165525535\n",
      "class 3 empirical mean = 11.968647682259597\n"
     ]
    }
   ],
   "source": [
    "M_mean = empirical_mean(2, 2, X_train, p, n_t_train)\n",
    "#matprint(M_mean)\n",
    "#print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utile pour les puissances négatives\n",
    "def power_diagonal_matrix(D, exponent):\n",
    "    diag = np.zeros(len(D))\n",
    "    for i in range(len(D)):\n",
    "        diag[i] = D[i][i]**exponent\n",
    "    \n",
    "    return np.diag(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ème étape\n",
    "Estimer $c$ et $\\mathcal{M}\\in\\mathbb{R}^{2k\\times 2k}$. \n",
    "$c=\\left[ c_{11},\\ldots,c_{km} \\right]^T\\in\\mathbb{R}^{km}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_c(n_t, n, nb_tasks, nb_classes):\n",
    "    c = np.empty(nb_tasks*nb_classes)\n",
    "    for task in range(nb_tasks):\n",
    "        for m in range(nb_classes):\n",
    "            c[task*nb_classes+m]=n_t[task][m]/n\n",
    "            \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = [0.25 0.25 0.25 0.25]T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.25, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.25, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.25]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = estimate_c(n_t, n, t, m)\n",
    "print(f\"c = {c}T\")\n",
    "Dc = np.diag(c)\n",
    "Dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M_cal(n,p,Dc,M):\n",
    "    \"\"\"\n",
    "    renvoie la matrice M cursive estimée\n",
    "    \"\"\"\n",
    "    c0 = p/n\n",
    "    return 1/c0*np.power(Dc, 1/2).dot(np.transpose(M)).dot(M).dot(np.power(Dc, 1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5642.08  14284.1  11002.2   8989.2  \n",
      "14284.1  36171.7  27859.8  22762.7  \n",
      "11002.2  27859.8    21459  17532.9  \n",
      " 8989.2  22762.7  17532.9  14326.2  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_matrix = compute_M_cal(n,p,Dc,M_mean)\n",
    "matprint(correlation_matrix)\n",
    "plt.imshow(correlation_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cmap est bizarre, mais peut-être que c'est bon je sais pas.\n",
    "\n",
    "## 3ème étape\n",
    "Let's compute optimal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a revoir\n",
    "\n",
    "def label_evaluation(nb_tasks, nb_classes, Dc, M_estimated):\n",
    "    \"\"\"\n",
    "    Evalue le label y pour une tache t et une classe l donnée\n",
    "    Comme ca qu'il faut écrire e_t1 ?\n",
    "    \"\"\"\n",
    "    inverse = np.linalg.inv(M_estimated+np.identity(nb_classes*nb_tasks))\n",
    "    power_dc = power_diagonal_matrix(Dc, -1/2)\n",
    "    et1_et2 = np.zeros((nb_tasks*nb_classes,1))\n",
    "    et1_et2[0] = 1\n",
    "    et1_et2[1] = -1\n",
    "    matprint(et1_et2)\n",
    "    y_1 = power_dc.dot(inverse).dot(M_estimated).dot(power_dc).dot(et1_et2)\n",
    "    et1_et2 = np.zeros((nb_tasks*nb_classes,1))\n",
    "    et1_et2[2] = 1\n",
    "    et1_et2[3] = -1\n",
    "    matprint(et1_et2)\n",
    "    y_2 = power_dc.dot(inverse).dot(M_estimated).dot(power_dc).dot(et1_et2)\n",
    "    y = np.empty((nb_tasks*nb_classes, 1))\n",
    "    y[0] = y_1[0]\n",
    "    y[1] = y_1[1]\n",
    "    y[2] = y_2[2]\n",
    "    y[3] = y_2[3]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1  \n",
      "-1  \n",
      " 0  \n",
      " 0  \n",
      " 0  \n",
      " 0  \n",
      " 1  \n",
      "-1  \n",
      "optimal labels for a 2-task 2-class example with synthetic gaussian data : \n",
      "  1.9404  \n",
      "-2.67081  \n",
      " 1.33083  \n",
      "-1.69559  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = label_evaluation(t,m,Dc,correlation_matrix)\n",
    "print(\"optimal labels for a 2-task 2-class example with synthetic gaussian data : \")\n",
    "matprint(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ème étape\n",
    "Estimation des $m_{tj}$, étant les $k\\times m$ moyennes estimées pour modéliser nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymptotic_mean(nb_tasks, nb_classes, y_tilde, Dc, correlation_matrix, t, j):\n",
    "    \"\"\"\n",
    "    compute asymptotic mean m_tj\n",
    "    t current task\n",
    "    j current class\n",
    "    \"\"\"\n",
    "    y_transpose = np.transpose(y_tilde)\n",
    "    etj = np.zeros((nb_tasks*nb_classes, 1))\n",
    "    etj[t*nb_classes+j] = 1\n",
    "    power_dc = power_diagonal_matrix(Dc, -1/2)\n",
    "    # Dc^1/2 ou Dc^{-1/2} ?\n",
    "    m_tj = y_transpose.dot(np.power(Dc, 1/2)).dot(correlation_matrix).dot(power_dc).dot(etj)\n",
    "    m_tj /= np.sqrt(y_transpose.dot(np.power(Dc, 1/2).dot(correlation_matrix).dot(np.power(Dc, 1/2)) + Dc).dot(y_tilde))\n",
    "    return m_tj[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_kl = -150.18167215229357\n",
      "m_kl = -380.3428571634085\n",
      "m_kl = -292.93852737702105\n",
      "m_kl = -239.35603600248592\n"
     ]
    }
   ],
   "source": [
    "for k in range(t):\n",
    "    for l in range(m):\n",
    "        print(f\"m_kl = {asymptotic_mean(t, m, y, Dc, correlation_matrix, k, l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs ont l'air particulièrement grandes par rapport aux moyennes empiriques trouvées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ème étape\n",
    "Calcul de $V$ le sous-espace engendrés par les $\\tau$ plus grands vecteurs propres. Dans le cas du binary MTL-SPCA, $V=\\frac{Xy}{\\lVert Xy \\rVert}=\\frac{XJ\\tilde{y}}{\\lVert XJ\\tilde{y} \\rVert}\\in\\mathbb{R}^{p\\times1}$, avec $J\\in\\mathbb{R}^{n\\times km}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_array(X, p, n, nb_tasks, nb_classes):\n",
    "    X_aggregated = np.empty((p, n))\n",
    "    class_1 = X[0][0]\n",
    "    for t in range(nb_tasks):\n",
    "        for l in range(nb_classes):\n",
    "            if t==0 and l==0:\n",
    "                continue\n",
    "            class_1 = np.append(class_1, X[t][l], 1)\n",
    "    X_aggregated = class_1\n",
    "    return X_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 320)\n"
     ]
    }
   ],
   "source": [
    "X_train_aggregated = aggregate_array(X_train, p, n, t, m)\n",
    "X_test_aggregated = aggregate_array(X_train, p, n, t, m)\n",
    "print(X_train_aggregated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V=\\frac{Xy}{\\lVert Xy \\rVert}=\\frac{XJ\\tilde{y}}{\\lVert XJ\\tilde{y} \\rVert}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_V(y_tilde, X, J):\n",
    "    xy_product = X.dot(J).dot(y_tilde)\n",
    "    return xy_product/np.linalg.norm(xy_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_J(nb_classes, nb_tasks, n, n_t):\n",
    "    left = 0\n",
    "    for i in range(2):\n",
    "        left += int(sum(n_t[i]))\n",
    "    J = np.zeros((left, nb_tasks*nb_tasks))\n",
    "    for t in range(nb_tasks):\n",
    "            for j in range(nb_classes):\n",
    "                for i in range((t*nb_classes+j)*n_t[t][j], n_t[t][j]+(t*nb_classes+j)*n_t[t][j]):\n",
    "                    J[i][t*nb_classes+j] = 1\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = create_J(m, t, n, n_t_train)\n",
    "#matprint(J)\n",
    "#x = np.random.normal(0, 1, size=(p,1))\n",
    "#compute_score(y, J, X, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.222761  \n",
      "-0.224577  \n",
      "-0.226706  \n",
      "-0.223503  \n",
      "-0.225771  \n",
      "-0.219824  \n",
      "-0.223902  \n",
      "-0.222025  \n",
      " -0.22642  \n",
      "-0.224582  \n",
      "-0.219297  \n",
      "-0.225509  \n",
      "-0.228634  \n",
      "-0.221037  \n",
      "-0.223229  \n",
      "-0.223977  \n",
      " -0.22307  \n",
      "-0.220864  \n",
      "-0.221391  \n",
      " -0.22481  \n"
     ]
    }
   ],
   "source": [
    "V = compute_V(y, X_train_aggregated, J)\n",
    "matprint(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ème étape\n",
    "Evaluation de nouvelles données $\\mathbf{x}$ : \n",
    "$V^T\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-150.18167215229357, -380.3428571634085], [-292.93852737702105, -239.35603600248592]]\n"
     ]
    }
   ],
   "source": [
    "m_t = []\n",
    "for k in range(t):\n",
    "    m_tj = []\n",
    "    for l in range(m):\n",
    "        m_tj.append(asymptotic_mean(t, m, y, Dc, correlation_matrix, k, l))\n",
    "    m_t.append(m_tj)\n",
    "\n",
    "print(m_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(V, x, m_t):\n",
    "    \"\"\"\n",
    "    x vecteur aléatoire que l'on veut classifier\n",
    "    On compare V^Tx à la moyenne des moyennes estimées pour les deux classes de la tache t\n",
    "    \"\"\"\n",
    "    x_projection = np.transpose(V).dot(x)\n",
    "    average_mean = 1/2*(m_t[0] + m_t[1])\n",
    "    return (1 if x_projection > average_mean else -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = np.random.normal(15, 1, size=(p, 1))\n",
    "print(X_test[0][0][0].shape)\n",
    "compute_score(V, X_test[0][0][0], m_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special as sp\n",
    "def qfunc(x):\n",
    "    return 0.5-0.5*sp.erf(x/np.sqrt(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(m_t):\n",
    "    return qfunc(1/2*(m_t[0] - m_t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(m_t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme distribué 2 tâches 2 classes\n",
    "Bien que certains résultats du précedent algorithmes sont particulèrement inquiétants, essayons de voir comment distribuer l'algorithme sur plusieurs serveurs.\n",
    "\n",
    "Par exemple un serveur demande les moyennes des autres serveurs pour pouvoir obtenir des meilleurs résultats en calculant la moyenne des ses données et la moyenne de toutes les moyennes avant de le renvoyer au serveur principal qui mettra à jour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
