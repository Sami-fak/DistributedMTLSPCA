{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matprint(mat, fmt=\"g\"):\n",
    "    \"\"\"\n",
    "    Pour une un print plus clair de la matrice\n",
    "    https://gist.github.com/braingineer/d801735dac07ff3ac4d746e1f218ab75\n",
    "    \"\"\"\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons des données synthétiques gaussiennes. Ici nous nous intéresserons dans un premier temps au cas où $m=2$. (Binary MTL Supervised Principal Component Analysis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme non distribué 2 taches 2 classes\n",
    "Fonctions pour générer des données synthétiques gaussiennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_random_matrix(m, k, p, l, h, random_seed=42):\n",
    "    \"\"\"\n",
    "    Retourne une matrice M de taille pxm*k contenant\n",
    "    les moyennes de chaque composante de chaque vecteur aléatoire\n",
    "    pour l'instant les moyennes sont tirées aléatoirement \n",
    "    suivant la loi uniforme sur l, h (pas convaincu par ce choix)\n",
    "    m est le nombre de classes\n",
    "    k est le nombre de taches\n",
    "    p est le nombre de features\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    M = []\n",
    "    tmp = []\n",
    "    for task in range(k):\n",
    "        tmp = []\n",
    "        for classe in range(m):\n",
    "            # on crée un vecteur de moyennes égales pour chaque classes\n",
    "            # de sorte à créer des classes gravitant autour d'une meme moyenne\n",
    "            tmp.append(np.ones((p,1))*np.random.uniform(low = 0.0, high = h))\n",
    "        M.append(tmp)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on prend des moyennes de la même façon que dans le papier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# ici on reprend les mêmes paramètres que dans la figure 2\n",
    "n_t = [[1000,1000], [50,50]]\n",
    "n = 2200\n",
    "p = 100\n",
    "m = 2\n",
    "t = 2\n",
    "# 2 taches, 2 classes, p = 20\n",
    "#M = mean_random_matrix(m, t, p, 0., 20.)\n",
    "#print(M)\n",
    "\n",
    "# pour plusieurs taches\n",
    "# M = mean_matrix(2, 3, 10, 0., 2.)\n",
    "# print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "def mean_matrix(beta, p):\n",
    "    \"\"\"\n",
    "    Crée des vecteurs de moyennes de la meme facon que dans la figure 2 du papier\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    #mu_1 = np.ones((p,1))*np.random.uniform(low = 0.0, high = 10.)\n",
    "    mu_1 = np.zeros((p,1))\n",
    "    mu_1[0]= 1\n",
    "    perpendicular_vector = np.zeros((p,1))\n",
    "    perpendicular_vector[-1] = 1\n",
    "    mu_2 = beta*mu_1+np.sqrt(1-beta**2)*perpendicular_vector\n",
    "    M = [[mu_1, -mu_1], [mu_2, -mu_2]]\n",
    "    return M\n",
    "M = mean_matrix(beta, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_synthetic_data(n, p, m, t, n_t, M):\n",
    "    \"\"\"\n",
    "    Renvoie un tableau de données synthétiques gaussiennes. X[0] accède aux données de la premiere tache.\n",
    "    X[0][1] accede aux données de la deuxieme classe de la premiere tache.\n",
    "    (vecteurs gaussiens de taille n_j * p tq sum(n_j for j) = n)\n",
    "    à partir du nombre d'échantillons n de taille p et du nombre de classe m.\n",
    "    t est le nombre de tâches\n",
    "    n_t est un vecteur comprenant les différentes valeurs n_j pour chaque task\n",
    "    M est la matrice des moyennes de chaque composante \n",
    "    de chaque vecteur aléatoire\n",
    "    \"\"\"\n",
    "    # assert(sum(n_j)/n==1\n",
    "    np.random.seed(55)\n",
    "    X = []\n",
    "    tmp = []\n",
    "    for task in range(t):\n",
    "        # pour une tache on a m classes\n",
    "        tmp = []\n",
    "        for k in range(m):\n",
    "            X_k = np.empty((n_t[task][k], p))\n",
    "            # on prendra la transposée a la fin\n",
    "            #print( n_t[task][k])\n",
    "            for j in range(n_t[task][k]):\n",
    "                # on crée n_j[task][k] vecteurs aléatoires de taille 1xp\n",
    "                # std = 1?\n",
    "                X_k[j] = np.random.normal(M[task][k][0], 1, size=(1, p))\n",
    "                # indice 0 parce que c'est toujours la meme moyenne dans M (pour l'instant ?)\n",
    "            X_k = np.transpose(X_k)\n",
    "            #print(k)\n",
    "            tmp.append(X_k)\n",
    "            # print(\"tmp = \", tmp)\n",
    "        X.append(tmp)\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gaussian_synthetic_data(n, p, m, t, n_t, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "for k in range(t):\n",
    "    for l in range(m):\n",
    "        # on normalise les colonnes\n",
    "        X[k][l] = normalize(X[k][l], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(X, split_rate, nb_tasks, nb_classes):\n",
    "    \"\"\"\n",
    "    Retourne une matrice de données de tests, et une matrice d'entrainement\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    tmp_test = []\n",
    "    tmp_train = []\n",
    "    n_t_train = []\n",
    "    n_t_test = []\n",
    "    for t in range(nb_tasks):\n",
    "        tmp_test = []\n",
    "        tmp_train = []\n",
    "        tmp_nt_train = []\n",
    "        tmp_nt_test = []\n",
    "        for l in range(nb_classes):\n",
    "            decoupe = int(split_rate*X[t][l].shape[1])\n",
    "            tmp_train.append(X[t][l][:, :decoupe])\n",
    "            tmp_test.append(X[t][l][:, decoupe:])\n",
    "            tmp_nt_train.append(decoupe)\n",
    "            tmp_nt_test.append(X[t][l].shape[1]-decoupe)\n",
    "        n_t_train.append(tmp_nt_train)\n",
    "        n_t_test.append(tmp_nt_test)\n",
    "        X_train.append(tmp_train)\n",
    "        X_test.append(tmp_test)\n",
    "    return X_train, X_test, n_t_train, n_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 200)"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, n_t_train, n_t_test = train_test_split_data(X, 0.8, 2, 2)\n",
    "n_t_train\n",
    "X_test[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut aussi créer le vecteur $\\tilde{y}\\in\\mathbb{R}^{2k}$, qui contiendra les labels associées aux données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(nb_tasks, nb_classes):\n",
    "    \"\"\"\n",
    "    Crée le vecteurs y_tilde contenant les labels associés aux données.\n",
    "    Ici on le fait pour deux 2 tâches et pour deux classes.\n",
    "    \"\"\"\n",
    "    y = np.empty((nb_classes*nb_tasks))\n",
    "    for t in range(0, nb_classes*nb_tasks-1, 2):\n",
    "        y[t] = -1\n",
    "        y[t+1] = 1\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "y = create_labels(t,m)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ère etape\n",
    "Calcul des moyennes empiriques, et calcul de la matrice $M\\in\\mathbb{R}^{p\\times 2k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas fait le cas du j=j' mais j'ai pas l'impression que c'est nécessaire en tout cas pas ici ?\n",
    "\n",
    "def empirical_mean(nb_tasks, nb_classes, X, p, n_t):\n",
    "    \"\"\"\n",
    "    compute empirical mean for data X\n",
    "    return an 1xp vector being the empirical mean for the random vector X_{tj}\n",
    "    retourne la matrice M\n",
    "    \"\"\"\n",
    "    M = np.empty((nb_classes*nb_tasks, p))\n",
    "    for t in range(nb_tasks):\n",
    "        for l in range(nb_classes):\n",
    "            #print(X[t][l].dot(np.ones((n_t[t][l]))).shape)\n",
    "            # print(t*nb_classes+l)\n",
    "            M[t*nb_tasks+l] = X[t][l].dot(np.ones((n_t[t][l])))\n",
    "            M[t*nb_tasks+l] /= n_t[t][l]\n",
    "            print(f\"class {t*nb_tasks+l} empirical mean = {np.mean(M[t*nb_tasks+l])}\")\n",
    "    return np.transpose(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 empirical mean = 0.022350010984483606\n",
      "class 1 empirical mean = -0.0224205644993353\n",
      "class 2 empirical mean = 0.016185171593039286\n",
      "class 3 empirical mean = -0.01464144449354975\n"
     ]
    }
   ],
   "source": [
    "M_mean = empirical_mean(t, m, X_train, p, n_t_train)\n",
    "#matprint(M_mean)\n",
    "#print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utile pour les puissances négatives\n",
    "def power_diagonal_matrix(D, exponent):\n",
    "    diag = np.zeros(len(D))\n",
    "    for i in range(len(D)):\n",
    "        diag[i] = D[i][i]**exponent\n",
    "    \n",
    "    return np.diag(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ème étape\n",
    "Estimer $c$ et $\\mathcal{M}\\in\\mathbb{R}^{2k\\times 2k}$. \n",
    "$c=\\left[ c_{11},\\ldots,c_{km} \\right]^T\\in\\mathbb{R}^{km}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_c(n_t, n, nb_tasks, nb_classes):\n",
    "    c = np.empty(nb_tasks*nb_classes)\n",
    "    for task in range(nb_tasks):\n",
    "        for m in range(nb_classes):\n",
    "            c[task*nb_classes+m]=n_t[task][m]/n\n",
    "            \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = [0.45454545 0.45454545 0.02272727 0.02272727]T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.45454545, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.45454545, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.02272727, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.02272727]])"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = estimate_c(n_t, n, t, m)\n",
    "print(f\"c = {c}T\")\n",
    "Dc = np.diag(c)\n",
    "Dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M_cal(n,p,Dc,M, display=False):\n",
    "    \"\"\"\n",
    "    renvoie la matrice M cursive estimée\n",
    "    \"\"\"\n",
    "    c0 = p/n\n",
    "    correlation_matrix = 1/c0*np.power(Dc, 1/2).dot(np.transpose(M)).dot(M).dot(np.power(Dc, 1/2))\n",
    "    if display==True:\n",
    "        plt.imshow(correlation_matrix)\n",
    "        plt.show()\n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.499774   -0.501085   0.0811489  -0.0730522  \n",
      " -0.501085    0.503007  -0.0805099   0.0733797  \n",
      " 0.0811489  -0.0805099   0.0366856  -0.0100373  \n",
      "-0.0730522   0.0733797  -0.0100373   0.0351202  \n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = compute_M_cal(n,p,Dc,M_mean)\n",
    "matprint(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cmap est bizarre, mais peut-être que c'est bon je sais pas.\n",
    "\n",
    "## 3ème étape\n",
    "Let's compute optimal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a revoir\n",
    "\n",
    "def label_evaluation(nb_tasks, nb_classes, Dc, M_estimated):\n",
    "    \"\"\"\n",
    "    Evalue le label y pour une tache t pour 2 classes\n",
    "    \"\"\"\n",
    "    inverse = np.linalg.inv(M_estimated+np.identity(nb_classes*nb_tasks))\n",
    "    power_dc = power_diagonal_matrix(Dc, -1/2)\n",
    "    et1_et2 = np.zeros((nb_tasks*nb_classes,1))\n",
    "    y = np.empty((nb_tasks*nb_classes, 1))\n",
    "    for t in range(nb_tasks):\n",
    "        et1_et2 = np.zeros((nb_tasks*nb_classes,1))\n",
    "        for l in range(nb_classes):\n",
    "            #print(t*nb_tasks+l)\n",
    "            et1_et2[t*nb_tasks+l] = 1 if l == 0 else -1\n",
    "        #print(et1_et2)\n",
    "        y[t*nb_tasks] = (power_dc.dot(inverse).dot(M_estimated).dot(power_dc).dot(et1_et2))[t*nb_tasks]\n",
    "        y[t*nb_tasks+1] = (power_dc.dot(inverse).dot(M_estimated).dot(power_dc).dot(et1_et2))[t*nb_tasks+1]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal labels for a 2-task 2-class example with synthetic gaussian data : \n",
      " 1.08691  \n",
      "-1.09056  \n",
      " 1.45867  \n",
      "-1.44234  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = label_evaluation(t,m,Dc,correlation_matrix)\n",
    "print(\"optimal labels for a 2-task 2-class example with synthetic gaussian data : \")\n",
    "matprint(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ème étape\n",
    "Estimation des $m_{tj}$, étant les $k\\times m$ moyennes estimées pour modéliser nos données.\n",
    "0.542878  \n",
    "-1.09056  \n",
    "  1.2875  \n",
    "-1.44234 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymptotic_mean(nb_tasks, nb_classes, y_tilde, Dc, correlation_matrix, t, j):\n",
    "    \"\"\"\n",
    "    compute asymptotic mean m_tj\n",
    "    t current task\n",
    "    j current class\n",
    "    \"\"\"\n",
    "    y_transpose = np.transpose(y_tilde)\n",
    "    etj = np.zeros((nb_tasks*nb_classes, 1))\n",
    "    etj[t*nb_tasks+j] = 1\n",
    "    power_dc = power_diagonal_matrix(Dc, -1/2)\n",
    "    # Dc^1/2 ou Dc^{-1/2} ?\n",
    "    m_tj = y_transpose.dot(np.power(Dc, 1/2)).dot(correlation_matrix).dot(power_dc).dot(etj)\n",
    "    m_tj /= np.sqrt(y_transpose.dot(np.power(Dc, 1/2).dot(correlation_matrix).dot(np.power(Dc, 1/2)) + Dc).dot(y_tilde))\n",
    "    return m_tj[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_kl = 0.7423842398752266\n",
      "m_kl = -0.744610764908286\n",
      "m_kl = 0.5569966666182359\n",
      "m_kl = -0.5069543641366305\n"
     ]
    }
   ],
   "source": [
    "for k in range(t):\n",
    "    for l in range(m):\n",
    "        print(f\"m_kl = {asymptotic_mean(t, m, y, Dc, correlation_matrix, k, l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs ont l'air particulièrement grandes par rapport aux moyennes empiriques trouvées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ème étape\n",
    "Calcul de $V$ le sous-espace engendrés par les $\\tau$ plus grands vecteurs propres. Dans le cas du binary MTL-SPCA, $V=\\frac{Xy}{\\lVert Xy \\rVert}=\\frac{XJ\\tilde{y}}{\\lVert XJ\\tilde{y} \\rVert}\\in\\mathbb{R}^{p\\times1}$, avec $J\\in\\mathbb{R}^{n\\times km}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_array(X, p, n, nb_tasks, nb_classes):\n",
    "    X_aggregated = np.empty((p, n))\n",
    "    class_1 = X[0][0]\n",
    "    for t in range(nb_tasks):\n",
    "        for l in range(nb_classes):\n",
    "            if t==0 and l==0:\n",
    "                continue\n",
    "            class_1 = np.append(class_1, X[t][l], 1)\n",
    "    X_aggregated = class_1\n",
    "    return X_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1680)\n"
     ]
    }
   ],
   "source": [
    "X_train_aggregated = aggregate_array(X_train, p, n, t, m)\n",
    "X_test_aggregated = aggregate_array(X_train, p, n, t, m)\n",
    "print(X_train_aggregated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V=\\frac{Xy}{\\lVert Xy \\rVert}=\\frac{XJ\\tilde{y}}{\\lVert XJ\\tilde{y} \\rVert}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_V(y_tilde, X, J):\n",
    "    xy_product = X.dot(J).dot(y_tilde)\n",
    "    return xy_product/np.linalg.norm(xy_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_J(nb_classes, nb_tasks, n, n_t):\n",
    "    left = 0\n",
    "    for i in range(nb_tasks):\n",
    "        left += int(sum(n_t[i]))\n",
    "    J = np.zeros((left, nb_tasks*nb_classes))\n",
    "    #matprint(J)\n",
    "    for t in range(nb_tasks):\n",
    "        for j in range(nb_classes):\n",
    "            for i in range((t*nb_tasks+j)*n_t[t][j], n_t[t][j]+(t*nb_tasks+j)*n_t[t][j]):\n",
    "                #print(t*nb_tasks+j)\n",
    "                J[i][t*nb_tasks+j] = 1\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = create_J(m, t, n, n_t_train)\n",
    "#matprint(J)\n",
    "#x = np.random.normal(0, 1, size=(p,1))\n",
    "#compute_score(y, J, X, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = compute_V(y, X_train_aggregated, J)\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ème étape\n",
    "Evaluation de nouvelles données $\\mathbf{x}$ : \n",
    "$V^T\\mathbf{x}$\n",
    "\n",
    "On utilise les données du test set $X\\_test$. On obtient de très mauvais résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mt(t, m, y, Dc, correlation_matrix, k, l):\n",
    "    m_t = []\n",
    "    for k in range(t):\n",
    "        m_tj = []\n",
    "        for l in range(m):\n",
    "            m_tj.append(asymptotic_mean(t, m, y, Dc, correlation_matrix, k, l))\n",
    "        m_t.append(m_tj)\n",
    "\n",
    "    return m_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_t = create_mt(t, m, y, Dc, correlation_matrix, k, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(V, x, m_t):\n",
    "    \"\"\"\n",
    "    x vecteur aléatoire que l'on veut classifier\n",
    "    On compare V^Tx à la moyenne des moyennes estimées pour les deux classes de la tache t\n",
    "    \"\"\"\n",
    "    x_projection = np.transpose(V).dot(x)\n",
    "    average_mean = 1/2*(m_t[0] + m_t[1])\n",
    "    return (1 if x_projection > average_mean else -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special as sp\n",
    "def qfunc(x):\n",
    "    return 0.5-0.5*sp.erf(x/np.sqrt(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(m_t):\n",
    "    return qfunc(1/2*(m_t[0] - m_t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_rate(X_test, m_t, nb_tasks, nb_classes, n_t):\n",
    "    \"\"\"\n",
    "    Compute and plot classification error rate on test set\n",
    "    \"\"\"\n",
    "    rate = []\n",
    "    for t in range(nb_tasks):\n",
    "        n = sum(n_t[t])\n",
    "        error = 0\n",
    "        for l in range(nb_classes):\n",
    "            for i in range(n_t[t][l]):\n",
    "                # on prend la transposée pour pouvoir travailler avec les colonnes\n",
    "                score = compute_score(V, np.transpose(X_test[t][l])[i], m_t[t])\n",
    "                #print(score)\n",
    "                if (score == 1 and l == 1):\n",
    "                    error +=1\n",
    "                elif (score == -1 and l == 0):\n",
    "                    error += 1\n",
    "        rate.append(error/n)\n",
    "    \n",
    "    plt.scatter(range(nb_tasks), rate, label=\"empirical error\")\n",
    "    plt.scatter(range(nb_tasks), [error_rate(m_t[i]) for i in range(nb_tasks)], label=\"theoritical error\")\n",
    "    plt.grid()\n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim((-0.5, 0.5))\n",
    "    plt.legend()\n",
    "    plt.title(f\"Classification error rate per task\")\n",
    "\n",
    "    return rate, [error_rate(m_t[i]) for i in range(nb_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2], [0.017296897701682745])"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error_rate(X_test, m_t, t, m, n_t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017296897701682745"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate(m_t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme distribué 2 tâches 2 classes\n",
    "Bien que certains résultats du précedent algorithmes sont particulèrement inquiétants, essayons de voir comment distribuer l'algorithme sur plusieurs serveurs.\n",
    "\n",
    "Par exemple un serveur demande les moyennes des autres serveurs pour pouvoir obtenir des meilleurs résultats en calculant la moyenne des ses données et la moyenne de toutes les moyennes avant de le renvoyer au serveur principal qui mettra à jour le modèle.\n",
    "\n",
    "Prendre des données synthétiques pour la 1ère tâche à 2 classes, puis rappatrier une ou plusieurs moyennes pour les autres tasks. \n",
    "Faire des comparaisons, avec et sans federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serveur isolé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 empirical mean = 0.19723824457540726\n",
      "class 1 empirical mean = 0.47502147541022377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.2], [0.017296897701682745])"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 200\n",
    "p = 100\n",
    "m = 2\n",
    "t = 1\n",
    "n_t = [[100,100]]\n",
    "M = mean_random_matrix(m, t, p, 0., 0.5)\n",
    "X = gaussian_synthetic_data(n, p, m, t, n_t, M)\n",
    "X_train, X_test, n_t_train, n_t_test = train_test_split_data(X, 0.8, t, m)\n",
    "y = create_labels(t,m)\n",
    "M_mean = empirical_mean(t, m, X_train, p, n_t_train)\n",
    "c = estimate_c(n_t, n, t, m)\n",
    "Dc = np.diag(c)\n",
    "correlation_matrix = compute_M_cal(n,p,Dc,M_mean, display=False)\n",
    "y = label_evaluation(t,m,Dc,correlation_matrix)\n",
    "X_train_aggregated = aggregate_array(X_train, p, n, t, m)\n",
    "X_test_aggregated = aggregate_array(X_train, p, n, t, m)\n",
    "J = create_J(m, t, n, n_t_train)\n",
    "V = compute_V(y, X_train_aggregated, J)\n",
    "m_t = create_mt(t, m, y, Dc, correlation_matrix, k, l)\n",
    "plot_error_rate(X_test, m_t, t, m, n_t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 serveurs \n",
    "L'un des serveurs va demander les moyennes des autres pour entraîner le modèle sur ses données et sortir un résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
