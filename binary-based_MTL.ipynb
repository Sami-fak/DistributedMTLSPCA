{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matprint(mat, fmt=\"g\"):\n",
    "    \"\"\"\n",
    "    Pour une un print plus clair de la matrice\n",
    "    https://gist.github.com/braingineer/d801735dac07ff3ac4d746e1f218ab75\n",
    "    \"\"\"\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons des données synthétiques gaussiennes. Ici nous nous intéresserons dans un premier temps au cas où $m=2$. (Binary MTL Supervised Principal Component Analysis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inutile, puisque la première étape consiste à calculer les moyennes empiriques\n",
    "# enfait si c'est quand même utile pour générer les données X\n",
    "\n",
    "def mean_matrix(m, k, p, l, h):\n",
    "    \"\"\"\n",
    "    Retourne une matrice M de taille pxm*k contenant\n",
    "    les moyennes de chaque composante de chaque vecteur aléatoire\n",
    "    pour l'instant les moyennes sont tirées aléatoirement \n",
    "    suivant la loi uniforme sur l, h (pas convaincu par ce choix)\n",
    "    m est le nombre de classes\n",
    "    k est le nombre de taches\n",
    "    p est le nombre de features\n",
    "    \"\"\"\n",
    "    np.random.seed(55)\n",
    "    M = []\n",
    "    tmp = []\n",
    "    for task in range(k):\n",
    "        tmp = []\n",
    "        for classe in range(m):\n",
    "            # on crée un vecteur de moyennes égales pour chaque classes\n",
    "            # de sorte à créer des classes gravitant autour d'une meme moyenne\n",
    "            tmp.append(np.ones((p,1))*np.random.uniform(low = 0.0, high = 1.0))\n",
    "        M.append(tmp)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829],\n",
      "       [0.09310829]]), array([[0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592],\n",
      "       [0.97165592]])], [array([[0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998],\n",
      "       [0.48385998]]), array([[0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227],\n",
      "       [0.2425227]])]]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "n_t = [[100,100], [100,100], [100,100], [100,100]]\n",
    "n = 800\n",
    "p = 20\n",
    "m = 2\n",
    "t = 2\n",
    "# 2 taches, 2 classes, p = 20\n",
    "M = mean_matrix(m, t, p, 0., 2.)\n",
    "print(M)\n",
    "\n",
    "# pour plusieurs taches\n",
    "# M = mean_matrix(2, 3, 10, 0., 2.)\n",
    "# print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_synthetic_data(n, p, m, t, n_t, M):\n",
    "    \"\"\"\n",
    "    Renvoie un tableau de données synthétiques gaussiennes. X[0] accède aux données de la premiere tache.\n",
    "    X[0][1] accede aux données de la deuxieme classe de la premiere tache.\n",
    "    (vecteurs gaussiens de taille n_j * p tq sum(n_j for j) = n)\n",
    "    à partir du nombre d'échantillons n de taille p et du nombre de classe m.\n",
    "    t est le nombre de tâches\n",
    "    n_t est un vecteur comprenant les différentes valeurs n_j pour chaque task\n",
    "    M est la matrice des moyennes de chaque composante \n",
    "    de chaque vecteur aléatoire\n",
    "    \"\"\"\n",
    "    # assert(sum(n_j)/n==1\n",
    "    np.random.seed(55)\n",
    "    X = []\n",
    "    tmp = []\n",
    "    for task in range(t):\n",
    "        # pour une tache on a m classes\n",
    "        tmp = []\n",
    "        for k in range(m):\n",
    "            X_k = np.empty((n_t[task][k], p))\n",
    "            # on prendra la transposée a la fin\n",
    "            #print( n_t[task][k])\n",
    "            for j in range(n_t[task][k]):\n",
    "                # on crée n_j[task][k] vecteurs aléatoires de taille 1xp\n",
    "                # std = 1?\n",
    "                X_k[j] = np.random.normal(M[task][k][0], 1, size=(1, p))\n",
    "                # indice 0 parce que c'est toujours la meme moyenne dans M (pour l'instant ?)\n",
    "            X_k = np.transpose(X_k)\n",
    "            #print(k)\n",
    "            tmp.append(X_k)\n",
    "            # print(\"tmp = \", tmp)\n",
    "        X.append(tmp)\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[-1.53062283, -1.28899445, -0.54953049, ..., -0.69304351,\n",
       "          -0.26148744, -0.31801429],\n",
       "         [-0.00867565, -0.90034635, -0.71008325, ..., -0.5454225 ,\n",
       "          -1.22887874,  1.24980071],\n",
       "         [-1.71668281, -0.0763576 ,  0.99169746, ..., -0.16034256,\n",
       "          -0.15677109,  0.79994033],\n",
       "         ...,\n",
       "         [ 0.79546019,  0.88833412, -0.63493506, ...,  0.06933942,\n",
       "          -0.09249312, -1.03226742],\n",
       "         [ 0.98149013, -1.47808587,  0.00576858, ..., -0.17524952,\n",
       "          -1.13554115,  0.85082346],\n",
       "         [ 0.81532809, -1.06667849,  1.3915269 , ..., -0.35618595,\n",
       "           1.17381271,  1.15548296]]),\n",
       "  array([[ 0.80606558,  1.91934994, -1.09468132, ...,  1.78877157,\n",
       "           2.22004792,  2.3642421 ],\n",
       "         [ 0.25491674,  2.23307828,  1.07241878, ...,  1.25261133,\n",
       "           1.35528653,  1.34455153],\n",
       "         [-0.49400862,  0.9793958 ,  0.06961894, ...,  2.59109694,\n",
       "           0.73316318,  1.44336337],\n",
       "         ...,\n",
       "         [ 0.87415051,  0.82140651,  3.10032034, ...,  1.0718468 ,\n",
       "           2.48543425,  0.40758557],\n",
       "         [ 1.27092297,  2.01433597,  1.40704938, ...,  2.04511936,\n",
       "           1.96009782,  1.36666039],\n",
       "         [-0.26601258,  0.7430818 ,  1.05472077, ...,  2.38892035,\n",
       "           1.04242008,  1.46050615]])],\n",
       " [array([[ 0.80938564,  0.30030584, -0.46280951, ..., -1.01762786,\n",
       "           0.73995669,  1.17916644],\n",
       "         [ 0.96750486,  0.62431391,  0.3168587 , ...,  1.43931031,\n",
       "           0.96389901, -0.07247162],\n",
       "         [ 0.52295324, -0.79056254,  0.54141095, ..., -0.10022661,\n",
       "          -0.72160835,  0.22304795],\n",
       "         ...,\n",
       "         [ 0.23082127, -0.15376299,  2.1698154 , ...,  0.18948307,\n",
       "           1.87910001, -0.25593367],\n",
       "         [ 1.16242533,  0.22495087, -0.62334822, ...,  1.03584187,\n",
       "           1.46560443, -0.13770806],\n",
       "         [ 0.87847923, -0.50605188, -0.08968908, ...,  2.44188413,\n",
       "           2.60542525,  1.58772467]]),\n",
       "  array([[ 0.11812896, -0.15514926, -0.7408364 , ...,  2.20500389,\n",
       "           1.08798122, -0.02376368],\n",
       "         [ 0.32683415,  0.49350904, -0.24364132, ..., -0.38210053,\n",
       "          -0.74508005,  0.6480765 ],\n",
       "         [ 1.89448115,  1.57507827, -1.86320915, ...,  0.99181616,\n",
       "          -0.73510734,  0.63842778],\n",
       "         ...,\n",
       "         [-0.28536718, -0.86277648, -1.01146923, ...,  1.49562561,\n",
       "           0.19255876,  1.01650774],\n",
       "         [ 0.09522268, -0.88195698, -0.28498722, ..., -0.42523931,\n",
       "           0.65123466,  1.62164194],\n",
       "         [ 1.39338852,  0.5324996 , -0.48520502, ...,  1.3925486 ,\n",
       "          -0.58171657, -1.16207695]])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test \n",
    "X = gaussian_synthetic_data(n, p, m, t, n_t, M)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation des données pour chaque tâche\n",
    "\n",
    "# inutile\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "for i in range(len(X)):\n",
    "    for k in range(len(X[i])):\n",
    "        X[i][k] = normalize(X[i][k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X est une matrice de taille $p\\times n$, avec $p=20$, le nombre de features, et $n=80$. $c_0=1/4$\n",
    "\n",
    "Il faut aussi créer le vecteur $\\tilde{y}\\in\\mathbb{R}^{2k}$, qui contiendra les labels associées aux données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(nb_tasks, nb_classes):\n",
    "    \"\"\"\n",
    "    Crée le vecteurs y_tilde contenant les labels associés aux données.\n",
    "    Ici on le fait pour deux 2 tâches et pour deux classes.\n",
    "    \"\"\"\n",
    "    y = np.empty((nb_classes*nb_tasks))\n",
    "    for t in range(0, nb_classes*nb_tasks-1, 2):\n",
    "        y[t] = -1\n",
    "        y[t+1] = 1\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = create_labels(2,2)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(X, test_size=0.2, random_state=42)\n",
    "# découpe pas comme je le veux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ère etape\n",
    "Calcul des moyennes empiriques, et calcul de la matrice $M\\in\\mathbb{R}^{p\\times 2k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.ones((n_t[1][1], 1)))\n",
    "X[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas fait le cas du j=j' mais j'ai pas l'impression que c'est nécessaire en tout cas pas ici ?\n",
    "\n",
    "def empirical_mean(nb_tasks, nb_classes, X, p, n_t):\n",
    "    \"\"\"\n",
    "    compute empirical mean for data X\n",
    "    return an 1xp vector being the empirical mean for the random vector X_{tj}\n",
    "    retourne la matrice M\n",
    "    \"\"\"\n",
    "    M = np.empty((nb_classes*nb_tasks, p))\n",
    "    for t in range(nb_tasks):\n",
    "        for l in range(nb_classes):\n",
    "            #print(X[t][l].dot(np.ones((n_t[t][l]))).shape)\n",
    "            # print(t*nb_classes+l)\n",
    "            M[t*nb_classes+l] = X[t][l].dot(np.ones((n_t[t][l])))\n",
    "            M[t*nb_classes+l] /= n_t[t][l]\n",
    "            print(f\"class {t*nb_classes+l} empirical mean = {np.mean(M[t*nb_classes+l])}\")\n",
    "    return np.transpose(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 empirical mean = 0.10269756940790972\n",
      "class 1 empirical mean = 0.991108749909227\n",
      "class 2 empirical mean = 0.4950598584697935\n",
      "class 3 empirical mean = 0.2421534514433296\n",
      "  0.182699   1.06967  0.483733  0.0736078  \n",
      " 0.0163268   1.02035   0.45356   0.151434  \n",
      " 0.0976678   1.10747  0.481081   0.332247  \n",
      "  0.124627  0.966628  0.710325   0.432174  \n",
      " 0.0684938   1.09044  0.408631  0.0651199  \n",
      "  0.112691  0.831602  0.618425   0.188997  \n",
      "  0.192282  0.973948   0.52177   0.368502  \n",
      "  0.203196   1.00957  0.448227   0.281191  \n",
      "-0.0995654   1.01232  0.333477   0.215661  \n",
      " -0.016813  0.986572  0.448624   0.226877  \n",
      "  0.126558   0.94448  0.503978   0.195808  \n",
      " 0.0470105  0.832099  0.408064   0.397331  \n",
      " 0.0493442   1.17375  0.510282   0.374944  \n",
      "  0.092401  0.828034  0.405676   0.273992  \n",
      " 0.0416406  0.951052  0.554584   0.192112  \n",
      "  0.195302     1.064  0.516971   0.325644  \n",
      "  0.151426  0.897434  0.435352     0.2222  \n",
      "  0.200537   1.04774  0.577451    0.14556  \n",
      "  0.238924  0.956396  0.480691   0.124644  \n",
      "  0.029203   1.05863  0.600295   0.255025  \n"
     ]
    }
   ],
   "source": [
    "M_mean = empirical_mean(2, 2, X, p, n_t)\n",
    "matprint(M_mean)\n",
    "#print(M)\n",
    "# la premiere moyenne du vecteur mu_{11} est bizarre puisqu'on devrait se rapprocher 0.97 ah non c'est bon enfait "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utile pour les puissances négatives\n",
    "def power_diagonal_matrix(D, exponent):\n",
    "    diag = np.zeros(len(D))\n",
    "    for i in range(len(D)):\n",
    "        diag[i] = D[i][i]**exponent\n",
    "    \n",
    "    return np.diag(diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ème étape\n",
    "Estimer $c$ et $\\mathcal{M}\\in\\mathbb{R}^{2k\\times 2k}$. \n",
    "$c=\\left[ c_{11},\\ldots,c_{km} \\right]^T\\in\\mathbb{R}^{km}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_c(n_t, n, nb_tasks, nb_classes):\n",
    "    c = np.empty(nb_tasks*nb_classes)\n",
    "    for task in range(nb_tasks):\n",
    "        for m in range(nb_classes):\n",
    "            c[task*nb_classes+m]=n_t[task][m]/n\n",
    "            \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = [0.125 0.125 0.125 0.125]T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.125, 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.125, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.125, 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.125]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = estimate_c(n_t, n, t, m)\n",
    "print(f\"c = {c}T\")\n",
    "Dc = np.diag(c)\n",
    "Dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M_cal(n,p,Dc,M):\n",
    "    \"\"\"\n",
    "    renvoie la matrice M cursive estimée\n",
    "    \"\"\"\n",
    "    c0 = p/n\n",
    "    return 1/c0*np.power(Dc, 1/2).dot(np.transpose(M)).dot(M).dot(np.power(Dc, 1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.77361  10.1503  5.31713  2.44819  \n",
      "10.1503  99.0779  49.0961  23.9244  \n",
      "5.31713  49.0961  25.2273   12.193  \n",
      "2.44819  23.9244   12.193  6.92135  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAD8CAYAAAB6iWHJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANEElEQVR4nO3df+hd9X3H8edrMbVDS3VaMMRUO5SyUjatIdoJQ2wFlWJG60b8o2qxhJW62rHC2g0c6192f7RQLB3plKmU1k6rzYqjpKi0hemMIVo1s2bCMCjTqo2GdnZf+94f9+iuN5+vibnnnvv98XzA5XvOPZ/7fX8uSV4595xzzztVhSRN+q15T0DS0mQ4SGoyHCQ1GQ6SmgwHSU2Gg6SmqcIhye8k2ZHkie7n8YuMezXJ7u6xfZqakoaRaa5zSPL3wAtVdV2SzwPHV9VfNcYdqKpjp5inpIFNGw6PA+dV1TNJ1gH3VtV7G+MMB2mZmTYcflFVx42tv1hVB320SLIA7AYWgOuq6s5Fft9WYGu3etZKPCByzLwnMEOvzHsCM7Iw7wnM0G/g51X1rta2ow714iQ/BE5qbPqbtzCHd1fV00l+F7g7yU+r6j8nB1XVNmAbwJqk3v4WCiwXZ897AjP05LwnMCPPzXsCM/Qy/Ndi2w4ZDlX14cW2JfnvJOvGPlY8u8jveLr7+WSSe4EzgYPCQdLSMe2e+3bgim75CuB7kwOSHJ/k6G75ROBc4LEp60qasWnD4TrggiRPABd06yTZmOQfuzG/B+xM8hBwD6NjDoaDtMRNdUByllbqMYc/nPcEZshjDsvPy/BgVW1sbVuJJwQk9cBwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1NRLOCS5MMnjSfZ2na8mtx+d5NZu+/1JTu2jrqTZmTockqwBvgZcBLwPuCzJ+yaGXQW8WFWnAV8BvjRtXUmz1ceewyZgb1U9WVW/Br4NbJ4Ysxm4qVu+DfhQkvRQW9KM9BEO64Gnxtb3dc81x1TVArAfOKGH2pJm5JAdrw5Daw9g8n73hzPmDb0y3a2Q5quPPYd9wIax9ZOBpxcbk+Qo4J3AC5O/qKq2VdXGqtpoOEjz1Uc4PACcnuQ9Sd4GbGHUJm/ceNu8S4G7a6l205EE9PCxoqoWklwN/ABYA9xYVY8m+SKws6q2AzcAtyTZy2iPYcu0dSXNlu3wBmY7vOXHdniSNMZwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoaqlfmlUmeS7K7e3yyj7qSZmfqu0+P9cq8gFF/igeSbK+qxyaG3lpVV09bT9Iw+uh49XqvTIAkr/XKnAyHt+QY4Ozp57bk7Fiid/vuxUdXZiuiW+6Y9wxm5/I32TZUr0yAjyV5OMltSTY0tpNka5KdSXb+bw8Tk3Tk+giHw+mD+S/AqVX1+8AP+f+O22980Vg7vLU9TEzSkRukV2ZVPV9Vr3Sr3wDO6qGupBkapFdmknVjq5cAe3qoK2mGhuqV+ZkklwALjHplXjltXUmz1cfZCqrqLuCuieeuHVv+AvCFPmpJGoZXSEpqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ19dUO78YkzyZ5ZJHtSfLVrl3ew0k+0EddSbPT157DPwEXvsn2i4DTu8dW4Os91ZU0I72EQ1X9iNFdpRezGbi5Ru4Djpu4Xb2kJWaoYw6H1TLPdnjS0jFUOBxOyzzb4UlLyFDhcMiWeZKWlqHCYTtweXfW4hxgf1U9M1BtSUegl45XSb4FnAecmGQf8LfAWoCq+gdG3bAuBvYCvwQ+0UddSbPTVzu8yw6xvYBP91FL0jC8QlJSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpaah2eOcl2Z9kd/e4to+6kmanl3tIMmqHdz1w85uM+XFVfaSnepJmbKh2eJKWmb72HA7HB5M8xKiZzeeq6tHJAUm2Mmq0y1HAkwNObjAfbTX/Whn++Y55z2A2VujbOqShwmEXcEpVHUhyMXAno47bb1BV24BtAEcnB7XLkzScQc5WVNVLVXWgW74LWJvkxCFqSzoyg4RDkpOSpFve1NV9fojako7MUO3wLgU+lWQB+BWwpeuCJWmJGqod3vWMTnVKWia8QlJSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpaepwSLIhyT1J9iR5NMk1jTFJ8tUke5M8nOQD09aVNFt93ENyAfjLqtqV5B3Ag0l2VNVjY2MuYtSn4nTgbODr3U9JS9TUew5V9UxV7eqWXwb2AOsnhm0Gbq6R+4Djkqybtrak2en1mEOSU4EzgfsnNq0Hnhpb38fBAUKSrUl2Jtn5mz4nJukt6y0ckhwL3A58tqpemtzceMlBfSuqaltVbayqjR4plearl3+DSdYyCoZvVtV3G0P2ARvG1k9m1FBX0hLVx9mKADcAe6rqy4sM2w5c3p21OAfYX1XPTFtb0uz0cbbiXODjwE+T7O6e+2vg3fB6O7y7gIuBvcAvgU/0UFfSDE0dDlX1E9rHFMbHFPDpaWtJGo7H/SQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKahmqHd16S/Ul2d49rp60rabaGaocH8OOq+kgP9SQNYKh2eJKWmT72HF73Ju3wAD6Y5CFGzWw+V1WPNl6/FdgKo9tZP9fn5JaIW+6Y9wxmZ6W+tSfmPYE56S0cDtEObxdwSlUdSHIxcCejjttvUFXbgG0Aa5KD2uVJGs4g7fCq6qWqOtAt3wWsTXJiH7UlzcYg7fCSnNSNI8mmru7z09aWNDtDtcO7FPhUkgXgV8CWrguWpCVqqHZ41wPXT1tL0nC8QlJSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpqY8bzL49yb8neahrh/d3jTFHJ7k1yd4k93f9LSQtYX3sObwCnF9VfwCcAVyY5JyJMVcBL1bVacBXgC/1UFfSDPXRDq9e60kBrO0ek3eW3gzc1C3fBnzotVvVS1qa+mpqs6a7Lf2zwI6qmmyHtx54CqCqFoD9wAl91JY0G72EQ1W9WlVnACcDm5K8f2JIay/hoL4VSbYm2Zlkp00tpPnq9WxFVf0CuBe4cGLTPmADQJKjgHcCLzRev62qNlbVRj9zSPPVx9mKdyU5rlv+beDDwH9MDNsOXNEtXwrcbccraWnrox3eOuCmJGsYhc13qur7Sb4I7Kyq7Yx6ad6SZC+jPYYtPdSVNEN9tMN7GDiz8fy1Y8v/A/zJtLUkDccrJCU1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTUP1yrwyyXNJdnePT05bV9Js9XH36dd6ZR5Ishb4SZJ/rar7JsbdWlVX91BP0gD6uPt0AYfqlSlpmeljz4GuZ8WDwGnA1xq9MgE+luSPgJ8Bf1FVTzV+z1Zga7d64GV4vI/5HaYTgZ/Pusjlsy5wsEHe1xys1PcFw763UxbbkD4bT3Wdr+4A/ryqHhl7/gTgQFW9kuTPgD+tqvN7K9yDJDurauO859E339fys1Te2yC9Mqvq+ap6pVv9BnBWn3Ul9W+QXplJ1o2tXgLsmbaupNkaqlfmZ5JcAiww6pV5ZQ91+7Zt3hOYEd/X8rMk3luvxxwkrRxeISmpyXCQ1LTqwyHJhUkeT7I3yefnPZ++JLkxybNJHjn06OUjyYYk9yTZ012uf82859SHw/kawuBzWs3HHLqDqD8DLgD2AQ8Al1XVY3OdWA+6C84OADdX1fvnPZ++dGe+1lXVriTvYHTx3R8v9z+zJAGOGf8aAnBN42sIg1ntew6bgL1V9WRV/Rr4NrB5znPqRVX9iNGZoRWlqp6pql3d8suMTouvn++splcjS+prCKs9HNYD45dx72MF/EVbLZKcCpwJtC7XX3aSrEmyG3gW2LHI1xAGs9rDIY3nVu/nrGUkybHA7cBnq+qlec+nD1X1alWdAZwMbEoy14+Dqz0c9gEbxtZPBp6e01x0mLrP5LcD36yq7857Pn1b7GsIQ1vt4fAAcHqS9yR5G7AF2D7nOelNdAfubgD2VNWX5z2fvhzO1xCGtqrDoaoWgKuBHzA6sPWdqnp0vrPqR5JvAf8GvDfJviRXzXtOPTkX+Dhw/tidxS6e96R6sA64J8nDjP7T2lFV35/nhFb1qUxJi1vVew6SFmc4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FS0/8BSJT24skvBQgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_matrix = compute_M_cal(n,p,Dc,M_mean)\n",
    "matprint(correlation_matrix)\n",
    "plt.imshow(correlation_matrix, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cmap est bizarre, mais peut-être que c'est bon je sais pas.\n",
    "\n",
    "## 3ème étape\n",
    "Let's compute optimal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_evaluation(nb_tasks, nb_classes, Dc, M_estimated):\n",
    "    \"\"\"\n",
    "    Evalue le label y pour une tache t et une classe l donnée\n",
    "    Comme ca qu'il faut écrire e_t1 ?\n",
    "    \"\"\"\n",
    "    inverse = np.linalg.inv(M_estimated+np.identity(nb_classes*nb_tasks))\n",
    "    power_dc = power_diagonal_matrix(Dc, -1/2)\n",
    "    et1_et2 = np.zeros((nb_tasks*nb_classes,1))\n",
    "    for t in range(nb_tasks):\n",
    "        et1_et2[t*nb_classes] = 1\n",
    "        et1_et2[t*nb_classes+1] = -1\n",
    "    #matprint(et1_et2)\n",
    "    y = power_dc.dot(inverse).dot(M_estimated).dot(power_dc).dot(et1_et2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal labels for a 2-task 2-class example with synthetic gaussian data : \n",
      " 4.01949  \n",
      "-5.63164  \n",
      " 2.20718  \n",
      "-3.99624  \n"
     ]
    }
   ],
   "source": [
    "y = label_evaluation(t,m,Dc,correlation_matrix)\n",
    "print(\"optimal labels for a 2-task 2-class example with synthetic gaussian data : \")\n",
    "matprint(y)\n",
    "#y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ème étape\n",
    "Estimation des $m_{tj}$, étant les $k\\times m$ moyennes estimées pour modéliser nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymptotic_mean(nb_tasks, nb_classes, y_tilde, Dc, correlation_matrix, t, j):\n",
    "    \"\"\"\n",
    "    compute asymptotic mean m_tj\n",
    "    t current task\n",
    "    j current class\n",
    "    \"\"\"\n",
    "    y_transpose = np.transpose(y_tilde)\n",
    "    etj = np.zeros((nb_tasks*nb_classes, 1))\n",
    "    etj[t*nb_classes+j] = 1\n",
    "    power_dc = power_diagonal_matrix(Dc, -1/2)\n",
    "    m_tj = y_transpose.dot(np.power(Dc, 1/2)).dot(correlation_matrix).dot(power_dc).dot(etj)\n",
    "    m_tj /= np.sqrt(y_transpose.dot(np.power(Dc, 1/2).dot(correlation_matrix).dot(np.power(Dc, 1/2)) + Dc).dot(y_tilde))\n",
    "    np.reshape(m_tj, 1)\n",
    "    return m_tj[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_kl = -2.631653642228215\n",
      "m_kl = -27.60823949705744\n",
      "m_kl = -13.582783544105135\n",
      "m_kl = -6.876692711545298\n"
     ]
    }
   ],
   "source": [
    "for k in range(t):\n",
    "    for l in range(m):\n",
    "        print(f\"m_kl = {asymptotic_mean(t, m, y, Dc, correlation_matrix, k, l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs ont l'air particulièrement grandes par rapport aux moyennes empiriques trouvées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ème étape\n",
    "Calcul de $V$ le sous-espace engendrés par les $\\tau$ plus grands vecteurs propres. Dans le cas du binary MTL-SPCA, $V=\\frac{Xy}{\\lVert Xy \\rVert}$ de rang 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_V(y_tilde, X):\n",
    "    xy_product = X.dot(y_tilde)\n",
    "    return xy_product/np.linalg.norm(xy_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la facon dont j'ai structuré X m'oblige à créer une fonction pour agréger X en un seul array de taille nxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,2,20,100) and (4,1) not aligned: 100 (dim 3) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-c9ad7a455026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-233-0c711ea5d4d9>\u001b[0m in \u001b[0;36mcompute_V\u001b[0;34m(y_tilde, X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mxy_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tilde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxy_product\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,2,20,100) and (4,1) not aligned: 100 (dim 3) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "V = compute_V(y, np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inutile\n",
    "\n",
    "def estimate_M(nb_task, nb_classes, n_j, X):\n",
    "    \"\"\"\n",
    "    Permet d'estimer M à partir des données X\n",
    "    \"\"\"\n",
    "    M_coef = 0.0\n",
    "    M = np.empty((nb_classes*nb_task, nb_classes*nb_task))\n",
    "    for k in range(nb_task):\n",
    "        for j in range(nb_classes):\n",
    "            for j_prime in range(nb_classes):\n",
    "                if j==j_prime:\n",
    "                    #print(np.transpose(X[k][j][0], (np.int(n_j[k][j]/2),1)))\n",
    "                    #print(X[k][j][:np.int(n_j[k][j]/2)])\n",
    "                    # 1x2 x 2x8 x 8x2 x 2x1 = 1x1\n",
    "                    M_coef = np.transpose(np.ones((np.int(n_j[k][j]/2), 1))).dot(np.transpose(X[k][j])[:np.int(n_j[k][j]/2)]).dot(np.transpose(np.transpose(X[k][j])[np.int(n_j[k][j]/2):np.int(n_j[k][j])])).dot(np.ones(np.int(n_j[k][j_prime]/2)))\n",
    "                else:                       \n",
    "                    #print(np.ones((n_j[k][j], 1)))\n",
    "                    #print(np.transpose(np.ones((n_j[k][j], 1))))\n",
    "                    #print(np.transpose(X[k][j]))\n",
    "                    M_coef = np.transpose(np.ones((n_j[k][j], 1))).dot(np.transpose(X[k][j])).dot(X[k][j_prime]).dot(np.ones(n_j[k][j_prime]))\n",
    "                M[j][j_prime] = M_coef\n",
    "                \n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the classification score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score(y, J, X, x):\n",
    "    \"\"\"\n",
    "    x vecteur aléatoire que l'on veut classifier\n",
    "    \"\"\"\n",
    "    return np.transpose(y).dot(np.transpose(J)).dot(np.transpose(X)).dot(x)/np.linalg.norm(y.dot(np.transpose(J).dot(np.tranpose(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_J(nb_classes, nb_tasks, t, j):\n",
    "    J = np.zeros((nb_classes, nb_tasks))\n",
    "    J[t][j] = 1\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  0  0  0  \n",
      "0  0  0  0  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (8,8) and (4,2) not aligned: 8 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-ab36ec136239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmatprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-61d4255beb17>\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(y, J, X, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (8,8) and (4,2) not aligned: 8 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "J = create_J(m, t, 0, 0)\n",
    "matprint(J)\n",
    "x = np.random.normal(0, 1, size=(p,1))\n",
    "compute_score(y, J, X, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
